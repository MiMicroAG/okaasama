#!/usr/bin/env python3
"""
AIç”»åƒèªè­˜ã‚’ä½¿ç”¨ã—ã¦ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‹ã‚‰ã€Œç”°ã€æ–‡å­—ã‚’æ¤œå‡ºã™ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
"""

import openai
import base64
import datetime
from typing import List, Dict, Optional
import json
import os
import re
import logging
import tkinter as tk
from tkinter import filedialog
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
from config_loader import config_loader
from PIL import Image, ImageEnhance, ImageFilter
import io

# HEICå¯¾å¿œã‚’è¿½åŠ 
try:
    from pillow_heif import register_heif_opener
    register_heif_opener()
    HEIC_SUPPORTED = True
except ImportError:
    HEIC_SUPPORTED = False
    print("è­¦å‘Š: pillow-heifãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„ãŸã‚ã€HEICãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¾ã›ã‚“")

class AICalendarAnalyzer:
    def __init__(self):
        """AI ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼è§£æã‚¯ãƒ©ã‚¹ã®åˆæœŸåŒ–"""
        # è¨­å®šã‚’èª­ã¿è¾¼ã¿
        openai_config = config_loader.get_openai_config()
        
        # OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–
        self.client = openai.OpenAI(
            api_key=openai_config['api_key'] or os.getenv('OPENAI_API_KEY'),
            base_url=openai_config['api_base'] or os.getenv('OPENAI_API_BASE')
        )
        self.model = openai_config['model']
        self.max_image_size_kb = openai_config['max_image_size_kb']
        self.analysis_result = ""
        self.found_dates = []
        
        # ãƒ­ã‚°è¨­å®šã‚’é©ç”¨
        config_loader.setup_logging()
        logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
        
    def encode_image(self, image_path: str) -> str:
        """
        ç”»åƒã‚’base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹ï¼ˆå‰å‡¦ç†ä»˜ãã€256KBä»¥å†…ã«åœ§ç¸®ï¼‰
        
        Args:
            image_path (str): ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            
        Returns:
            str: base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒãƒ‡ãƒ¼ã‚¿
        """
        max_file_size_kb = self.max_image_size_kb  # è¨­å®šã‹ã‚‰å–å¾—
        max_file_size_bytes = max_file_size_kb * 1024
        
        # ç”»åƒã‚’é–‹ã„ã¦å‰å‡¦ç†
        with Image.open(image_path) as img:
            # å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’å–å¾—
            original_size_bytes = os.path.getsize(image_path)
            original_size_kb = original_size_bytes / 1024
            print(f"ğŸ“ å…ƒç”»åƒã‚µã‚¤ã‚º: {original_size_kb:.1f}KB")
            
            # RGBãƒ¢ãƒ¼ãƒ‰ã«å¤‰æ›
            if img.mode != 'RGB':
                img = img.convert('RGB')
            
            # ç”»åƒã‚µã‚¤ã‚ºã‚’æœ€é©åŒ–ï¼ˆæœ€å¤§2048x2048ã«åˆ¶é™ï¼‰
            max_size = 2048
            if max(img.size) > max_size:
                ratio = max_size / max(img.size)
                new_size = (int(img.size[0] * ratio), int(img.size[1] * ratio))
                img = img.resize(new_size, Image.Resampling.LANCZOS)
            
            # ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã‚’å¼·èª¿
            enhancer = ImageEnhance.Contrast(img)
            img = enhancer.enhance(1.2)  # ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã‚’20%ä¸Šã’ã‚‹
            
            # ã‚·ãƒ£ãƒ¼ãƒ—ãƒã‚¹ã‚’å¼·èª¿
            enhancer = ImageEnhance.Sharpness(img)
            img = enhancer.enhance(1.1)  # ã‚·ãƒ£ãƒ¼ãƒ—ãƒã‚¹ã‚’10%ä¸Šã’ã‚‹
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒ256KBä»¥å†…ã«åã¾ã‚‹ã‚ˆã†ã«åœ§ç¸®
            quality = 95  # åˆæœŸå“è³ª
            min_quality = 30  # æœ€ä½å“è³ª
            size_reduction_step = 0.8  # ã‚µã‚¤ã‚ºå‰Šæ¸›ã‚¹ãƒ†ãƒƒãƒ—
            
            while quality >= min_quality:
                buffer = io.BytesIO()
                img.save(buffer, format='JPEG', quality=quality, optimize=True)
                buffer_size = buffer.tell()
                
                if buffer_size <= max_file_size_bytes:
                    print(f"âœ“ ç”»åƒåœ§ç¸®å®Œäº†: {buffer_size/1024:.1f}KB (å“è³ª: {quality})")
                    buffer.seek(0)
                    return base64.b64encode(buffer.getvalue()).decode('utf-8')
                
                # å“è³ªã‚’ä¸‹ã’ã‚‹
                quality -= 5
                if quality < min_quality:
                    break
            
            # å“è³ªã ã‘ã§ã¯åã¾ã‚‰ãªã„å ´åˆã€è§£åƒåº¦ã‚’ä¸‹ã’ã‚‹
            print(f"âš  å“è³ªèª¿æ•´ã ã‘ã§ã¯åã¾ã‚‰ãªã„ãŸã‚ã€è§£åƒåº¦ã‚’èª¿æ•´ã—ã¾ã™")
            original_size = img.size
            current_size = list(original_size)
            
            while current_size[0] > 800 and current_size[1] > 600:  # æœ€ä½ã‚µã‚¤ã‚º
                current_size = [int(s * size_reduction_step) for s in current_size]
                img_resized = img.resize(current_size, Image.Resampling.LANCZOS)
                
                # æœ€ä½å“è³ªã§è©¦ã™
                buffer = io.BytesIO()
                img_resized.save(buffer, format='JPEG', quality=min_quality, optimize=True)
                buffer_size = buffer.tell()
                
                if buffer_size <= max_file_size_bytes:
                    print(f"âœ“ è§£åƒåº¦èª¿æ•´å¾Œåœ§ç¸®å®Œäº†: {buffer_size/1024:.1f}KB ({current_size[0]}x{current_size[1]})")
                    buffer.seek(0)
                    return base64.b64encode(buffer.getvalue()).decode('utf-8')
            
            # æœ€çµ‚æ‰‹æ®µ: æœ€ä½å“è³ªãƒ»æœ€ä½è§£åƒåº¦ã§ä¿å­˜
            final_size = (800, 600)
            img_final = img.resize(final_size, Image.Resampling.LANCZOS)
            buffer = io.BytesIO()
            img_final.save(buffer, format='JPEG', quality=min_quality, optimize=True)
            buffer_size = buffer.tell()
            
            print(f"âœ“ æœ€çµ‚åœ§ç¸®å®Œäº†: {buffer_size/1024:.1f}KB (800x600, å“è³ª{min_quality})")
            buffer.seek(0)
            return base64.b64encode(buffer.getvalue()).decode('utf-8')
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=4, max=10),
        retry=retry_if_exception_type((openai.APIError, openai.APIConnectionError, openai.RateLimitError))
    )
    def analyze_calendar_image(self, image_path: str) -> str:
        """
        AIç”»åƒèªè­˜ã§ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‚’è§£æã™ã‚‹
        
        Args:
            image_path (str): ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ç”»åƒã®ãƒ‘ã‚¹
            
        Returns:
            str: AIè§£æçµæœ
        """
        try:
            # ç”»åƒã‚’base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
            base64_image = self.encode_image(image_path)
            
            print(f"AIç”»åƒèªè­˜ã§ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‚’è§£æä¸­...")
            
            # OpenAI Vision APIã«é€ä¿¡
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": """ã“ã®ç”»åƒã¯ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã®ç”»åƒã§ã™ã€‚ç”»åƒã‹ã‚‰æ­£ç¢ºã«èª­ã¿å–ã£ãŸå¹´æœˆæƒ…å ±ã‚’å„ªå…ˆã—ã¦ãã ã•ã„ã€‚

ã‚ãªãŸã¯å°‚é–€çš„ãªæ–‡å­—èªè­˜AIã§ã™ã€‚ä»¥ä¸‹ã®ä½œæ¥­ã‚’é«˜ã„ç²¾åº¦ã§è¡Œã£ã¦ãã ã•ã„ï¼š

ã€é‡è¦ã€‘ã¾ãšã€ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã®å¹´æœˆæƒ…å ±ã‚’æ­£ç¢ºã«èª­ã¿å–ã£ã¦ãã ã•ã„ï¼š

ã€å¹´æœˆæƒ…å ±ã®èª­ã¿å–ã‚Šæ‰‹é †ã€‘
1. ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã®ä¸­å¤®ä¸Šéƒ¨ã¾ãŸã¯ä¸Šéƒ¨ä¸­å¤®ã‚’æ¢ã™
2. å¤§ããªæ–‡å­—ã‚„ç›®ç«‹ã¤ä½ç½®ã«ã‚ã‚‹æ•°å­—ã‚’æ¢ã™
3. æœˆã®æƒ…å ±ï¼šé€šå¸¸ã€Œ8æœˆã€ã€Œ9æœˆã€ãªã©ã®å½¢å¼ï¼ˆæ—¥æœ¬èªï¼‰
4. å¹´ã®æƒ…å ±ï¼šé€šå¸¸ã€Œ2025å¹´ã€ãªã©ã®å½¢å¼ï¼ˆè¥¿æš¦ï¼‰
5. æœˆã®æ•°å­—ã®å³å´ã¾ãŸã¯ä¸‹å´ã«å¹´ã®æ•°å­—ãŒã‚ã‚‹å ´åˆãŒå¤šã„
6. ãƒ˜ãƒƒãƒ€ãƒ¼éƒ¨åˆ†ã‚„ã‚¿ã‚¤ãƒˆãƒ«éƒ¨åˆ†ã«å¹´æœˆãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã“ã¨ãŒå¤šã„

ã€å¹´æœˆãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€‘
- ç”»åƒå…¨ä½“ã‚’ãã¾ãªãç¢ºèª
- è§’ã‚„ç«¯ã®éƒ¨åˆ†ã‚‚ç¢ºèª
- å°ã•ãªæ–‡å­—ã‚„è–„ã„æ–‡å­—ã‚‚è¦‹é€ƒã•ãªã„
- ç”»åƒãŒåˆ‡ã‚Œã¦ã„ã‚‹å ´åˆã¯ã€è¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹ç¯„å›²ã§åˆ¤æ–­

ã€å¹´æœˆã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä¾‹ã€‘
- ã€Œ2025å¹´8æœˆã€
- ã€Œ2025å¹´ 8æœˆã€
- ã€Œ2025å¹´8æœˆã€
- ã€Œ2025å¹´8æœˆåº¦ã€
- ã€Œ2025å¹´8æœˆã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã€

ã€æ–‡å­—èªè­˜ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã€‘
1. ã€Œç”°ã€ã¨ã„ã†æ¼¢å­—ã‚’æ­£ç¢ºã«ç‰¹å®šã—ã¦ãã ã•ã„
2. ã€Œç”°ã€ã®ç‰¹å¾´ï¼š
   - ç”°ã®ä¸­å¤®ã«ã€Œåã€ã®ã‚ˆã†ãªåå­—ã®ç·šãŒã‚ã‚‹
   - ä¸Šä¸‹å·¦å³ã«å››è§’ã„æ ãŒã‚ã‚‹
   - ä¸Šä¸‹å·¦å³ã«å››è§’ã„æ ã¯äº¤å·®ã—ã¦ã„ã‚‹å ´åˆã‚‚ã€æ¬ è½ã—ã¦ã„ã‚‹å ´åˆã‚‚ã€é–“ãŒç©ºã„ã¦ã„ã‚‹å ´åˆã‚‚ã‚ã‚‹
   - å…¨ä½“ã¨ã—ã¦ã€Œç”°ã€ã®å½¢ã‚’ã—ã¦ã„ã‚‹

ã€ç¢ºèªæ‰‹é †ã€‘
1. ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã®å„æ—¥ä»˜ã‚»ãƒ«ã‚’1ã¤ãšã¤ç¢ºèª
2. å„ã‚»ãƒ«ã«æ‰‹æ›¸ãæ–‡å­—ãŒã‚ã‚‹ã‹ç¢ºèª
3. æ–‡å­—ã®å½¢çŠ¶ã‚’è©³ç´°ã«åˆ†æ
4. ã€Œç”°ã€ã®ç‰¹å¾´ã«åˆè‡´ã™ã‚‹ã‹åˆ¤æ–­
5. ç¢ºä¿¡åº¦ã‚’ä»¥ä¸‹ã®åŸºæº–ã§è©•ä¾¡ï¼š
   - high: æ˜ã‚‰ã‹ã«ã€Œç”°ã€ã®å½¢ã‚’ã—ã¦ã„ã‚‹
   - medium: ã€Œç”°ã€ã«ä¼¼ã¦ã„ã‚‹ãŒã€å¤šå°‘ã®æ›–æ˜§ã•ãŒã‚ã‚‹
   - low: ã€Œç”°ã€ã®å¯èƒ½æ€§ãŒã‚ã‚‹ãŒã€ä¸æ˜ç­
ã€å‡ºåŠ›å½¢å¼ã€‘
ä»¥ä¸‹ã®JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š

{
  "calendar_info": {
    "detected_year": èª­ã¿å–ã‚ŒãŸå¹´ï¼ˆæ•°å­—ã®ã¿ï¼‰,
    "detected_month": èª­ã¿å–ã‚ŒãŸæœˆï¼ˆæ•°å­—ã®ã¿ï¼‰,
    "year_month_text": "ç”»åƒã‹ã‚‰èª­ã¿å–ã£ãŸå¹´æœˆã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆä¾‹: 2025å¹´8æœˆï¼‰",
    "detection_confidence": "year_month_detection_confidence",
    "location": "å¹´æœˆæƒ…å ±ã®ä½ç½®ï¼ˆä¾‹: ä¸­å¤®ä¸Šéƒ¨ã€å³ä¸Šãªã©ï¼‰"
  },
  "found_dates": [
    {
      "day": æ—¥ä»˜ã®æ•°å­—ï¼ˆ1-31ï¼‰,
      "confidence": "high/medium/low",
      "description": "è¦‹ã¤ã‹ã£ãŸæ–‡å­—ã®è©³ç´°ãªèª¬æ˜",
      "location": "æ—¥ä»˜ã‚»ãƒ«ã®ä½ç½®ã®èª¬æ˜ï¼ˆä¾‹ï¼šå·¦ä¸Šã€ä¸­å¤®ãªã©ï¼‰"
    }
  ],
  "analysis": {
    "total_cells_checked": ç¢ºèªã—ãŸã‚»ãƒ«ã®ç·æ•°,
    "search_character": "ç”°",
    "search_method": "æ‰‹æ›¸ãæ–‡å­—ã®å½¢çŠ¶åˆ†æ",
    "confidence_threshold": "mediumä»¥ä¸Šã‚’æ¤œå‡ºå¯¾è±¡",
    "detected_year_month": "èª­ã¿å–ã‚ŒãŸå¹´æœˆæƒ…å ±",
    "notes": "å¹´æœˆæƒ…å ±ã®èª­ã¿å–ã‚Šçµæœã‚„ç‰¹è¨˜äº‹é …"
  }
}

ã€é‡è¦ã€‘
- å¹´æœˆæƒ…å ±ãŒæ¤œå‡ºã§ããªã‹ã£ãŸå ´åˆã¯ã€found_datesã‚’ç©ºã®é…åˆ—ã«ã—ã¦ãã ã•ã„
- æ—¥ä»˜ã¯ç”»åƒã‹ã‚‰èª­ã¿å–ã£ãŸå¹´æœˆã®ç¯„å›²å†…ã§æ¤œå‡ºã—ã¦ãã ã•ã„
- å‰æœˆã¾ãŸã¯ç¿Œæœˆã®è–„ã„æ–‡å­—ã®æ—¥ä»˜ã‚»ãƒ«ã¯å‡¦ç†å¯¾è±¡ã‹ã‚‰é™¤å¤–ã—ã¦ãã ã•ã„
- èƒŒæ™¯ãŒã‚°ãƒ¬ãƒ¼ã§æ–‡å­—ãŒç™½æŠœãã«ãªã£ã¦ã„ã‚‹æ—¥ä»˜ã‚»ãƒ«ã¯é™¤å¤–ã—ã¦ãã ã•ã„
- ãƒ¡ã‚¤ãƒ³ã®ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼å¹´æœˆã®æ—¥ä»˜ã®ã¿ã‚’å¯¾è±¡ã¨ã—ã¾ã™
- æ‰‹æ›¸ãæ–‡å­—ã®ã¿ã‚’å¯¾è±¡ï¼ˆå°åˆ·æ–‡å­—ã¯ç„¡è¦–ï¼‰
- ç¢ºä¿¡åº¦ãŒlowã‚‚å«ã‚ã‚‹
- è¤‡æ•°ã®ã€Œç”°ã€æ–‡å­—ãŒã‚ã‚‹å ´åˆã¯ã™ã¹ã¦æ¤œå‡º"""
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{base64_image}"
                                }
                            }
                        ]
                    }
                ],
                max_completion_tokens=2000
            )
            
            result = response.choices[0].message.content
            if result is None:
                result = ""
            self.analysis_result = result
            print(f"AIè§£æçµæœ:\n{result}")
            
            return result
            
        except openai.RateLimitError as e:
            print(f"OpenAIãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼: {e}")
            return ""
        except openai.APIConnectionError as e:
            print(f"OpenAIæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
            return ""
        except openai.APIError as e:
            print(f"OpenAI APIã‚¨ãƒ©ãƒ¼: {e}")
            return ""
        except Exception as e:
            print(f"AIç”»åƒèªè­˜ã§äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            import traceback
            traceback.print_exc()
            return ""
    
    def extract_dates_from_analysis(self, analysis_text: str) -> List[str]:
        """
        AIè§£æçµæœã‹ã‚‰æ—¥ä»˜ã‚’æŠ½å‡ºã™ã‚‹
        
        Args:
            analysis_text (str): AIè§£æçµæœã®ãƒ†ã‚­ã‚¹ãƒˆ
            
        Returns:
            List[str]: æ—¥ä»˜ã®ãƒªã‚¹ãƒˆï¼ˆYYYY-MM-DDå½¢å¼ï¼‰
        """
        found_dates = []
        detected_year = None
        detected_month = None
        
        try:
            # JSONå½¢å¼ã®å›ç­”ã‚’è§£æ
            json_match = re.search(r'\{.*\}', analysis_text, re.DOTALL)
            if json_match:
                json_str = json_match.group()
                data = json.loads(json_str)
                
                # å¹´æœˆæƒ…å ±ã®å‡¦ç†
                if 'calendar_info' in data:
                    calendar_info = data['calendar_info']
                    detected_year = calendar_info.get('detected_year')
                    detected_month = calendar_info.get('detected_month')
                    year_month_text = calendar_info.get('year_month_text', '')
                    
                    print(f"ğŸ“… å¹´æœˆæƒ…å ±æ¤œå‡º: {year_month_text}")
                    if detected_year and detected_month:
                        print(f"  æ¤œå‡ºå¹´: {detected_year}å¹´, æ¤œå‡ºæœˆ: {detected_month}æœˆ")
                        print(f"  ä½ç½®: {calendar_info.get('location', 'ä¸æ˜')}")
                        print(f"  ç¢ºä¿¡åº¦: {calendar_info.get('detection_confidence', 'ä¸æ˜')}")
                    else:
                        print("  âš  å¹´æœˆæƒ…å ±ã‚’èª­ã¿å–ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
                        print("  å¹´æœˆæƒ…å ±ãŒæ¤œå‡ºã§ããªã‹ã£ãŸãŸã‚ã€æ—¥ä»˜ã‚’ç™»éŒ²ã—ã¾ã›ã‚“")
                        return []  # å¹´æœˆãŒæ¤œå‡ºã§ããªã‹ã£ãŸå ´åˆã¯ç©ºãƒªã‚¹ãƒˆã‚’è¿”ã™
                
                # yearã¨monthã‚’ç¢ºå®š
                current_year = detected_year
                current_month = detected_month
                assert isinstance(current_year, int)
                assert isinstance(current_month, int)
                
                if 'found_dates' in data:
                    for item in data['found_dates']:
                        day = item.get('day')
                        confidence = item.get('confidence', 'low')
                        location = item.get('location', '')
                        
                        # ç¢ºä¿¡åº¦ãŒmediumä»¥ä¸Šã®å ´åˆã®ã¿æ¡ç”¨ï¼ˆhigh/mediumã®ã¿ï¼‰
                        if confidence in ['high', 'medium'] and day and 1 <= day <= 31:
                            # æœˆã®æ—¥æ•°ãƒã‚§ãƒƒã‚¯ã¨å‰æœˆç¿Œæœˆã®é™¤å¤–
                            try:
                                date_obj = datetime.date(current_year, current_month, day)
                                
                                # locationã‹ã‚‰æœˆæƒ…å ±ã‚’æŠ½å‡ºã—ã¦ãƒã‚§ãƒƒã‚¯
                                month_in_location = None
                                if 'æœˆ' in location:
                                    # ã€Œ8æœˆ28æ—¥ã€ã€Œ9æœˆ1æ—¥ã€ãªã©ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º
                                    month_match = re.search(r'(\d{1,2})æœˆ\d{1,2}æ—¥', location)
                                    if month_match:
                                        month_in_location = int(month_match.group(1))
                                
                                # locationã«æœˆãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã¦ã€detected_monthã¨ä¸€è‡´ã—ãªã„å ´åˆã¯é™¤å¤–
                                if month_in_location is not None and month_in_location != current_month:
                                    print(f"âš  ç¿Œæœˆ/å‰æœˆã®æ—¥ä»˜ã‚’é™¤å¤–: {month_in_location}æœˆ{day}æ—¥ (ãƒ¡ã‚¤ãƒ³ã¯{current_month}æœˆ)")
                                    continue
                                
                                # èƒŒæ™¯ãŒã‚°ãƒ¬ãƒ¼ã‚„ç™½æŠœããªã©ã®ã‚¹ã‚¿ã‚¤ãƒ«ãƒã‚§ãƒƒã‚¯
                                if any(keyword in location.lower() for keyword in ['ã‚°ãƒ¬ãƒ¼', 'ç™½æŠœã', 'è–„ã„', 'grey', 'whiteout', 'faint']):
                                    print(f"âš  ã‚°ãƒ¬ãƒ¼èƒŒæ™¯/ç™½æŠœãæ–‡å­—ã®æ—¥ä»˜ã‚’é™¤å¤–: {day}æ—¥ (ä½ç½®: {location})")
                                    continue
                                
                                found_dates.append(date_obj.isoformat())
                                print(f"âœ“ AIæ¤œå‡º: {current_year}å¹´{current_month}æœˆ{day}æ—¥ - ç¢ºä¿¡åº¦: {confidence}")
                                print(f"  èª¬æ˜: {item.get('description', 'N/A')}")
                            except ValueError:
                                # ç„¡åŠ¹ãªæ—¥ä»˜ï¼ˆä¾‹: 2æœˆ30æ—¥ãªã©ï¼‰ã¯ã‚¹ã‚­ãƒƒãƒ—
                                print(f"âš  ç„¡åŠ¹ãªæ—¥ä»˜ã‚’ã‚¹ã‚­ãƒƒãƒ—: {current_year}å¹´{current_month}æœˆ{day}æ—¥")
            
        except (json.JSONDecodeError, KeyError, ValueError, TypeError) as e:
            logging.error(f"JSONè§£æã‚¨ãƒ©ãƒ¼: {e} - å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ: {analysis_text[:200]}...")
            
            # JSONãŒå¤±æ•—ã—ãŸå ´åˆã‚‚ã€å¹´æœˆæƒ…å ±ãŒæ¤œå‡ºã§ããªã‹ã£ãŸã‚‰æ—¥ä»˜ã‚’æŠ½å‡ºã—ãªã„
            if not detected_year or not detected_month:
                print("  âš  å¹´æœˆæƒ…å ±ãŒæ¤œå‡ºã§ããªã‹ã£ãŸãŸã‚ã€æ—¥ä»˜ã‚’ç™»éŒ²ã—ã¾ã›ã‚“")
                return []
            
            # current_year/current_monthã‚’è¨­å®š
            current_year = detected_year
            current_month = detected_month
            
            # ã€Œç”°ã€ã¨ã„ã†æ–‡å­—ã®è¿‘ãã«ã‚ã‚‹æ•°å­—ã‚’æ¢ã™
            print("ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ—¥ä»˜ã‚’æŠ½å‡ºä¸­...")
            pattern = r'(\d{1,2})(?:\D*ç”°|\D*[\(\[]\D*ç”°\D*[\)\]])'
            matches = re.findall(pattern, analysis_text, re.IGNORECASE)
            
            for match in matches:
                try:
                    day = int(match)
                    if 1 <= day <= 31:
                        try:
                            date_obj = datetime.date(current_year, current_month, day)  # type: ignore  # type: ignore
                            date_str = date_obj.isoformat()
                            if date_str not in found_dates:
                                found_dates.append(date_str)
                                print(f"âœ“ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¤œå‡º: {current_year}å¹´{current_month}æœˆ{day}æ—¥")
                        except ValueError:
                            continue
                except ValueError:
                    continue
        
        except Exception as e:
            logging.error(f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
            import traceback
            traceback.print_exc()
        
        self.found_dates = found_dates
        return found_dates
    
    def save_results(self, output_path: str):
        """
        çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹
        
        Args:
            output_path (str): å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        results = {
            'analysis_result': self.analysis_result,
            'found_dates': self.found_dates,
            'analysis_time': datetime.datetime.now().isoformat()
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"çµæœã‚’ {output_path} ã«ä¿å­˜ã—ã¾ã—ãŸ")

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•° - ãƒ†ã‚¹ãƒˆç”¨"""
    print("AIã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ç”»åƒè§£æã‚·ã‚¹ãƒ†ãƒ ")
    print("ä½¿ç”¨æ–¹æ³•: ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ç”»åƒã‚’é¸æŠã—ã¦ãã ã•ã„")
    
    # tkinterã®ãƒ«ãƒ¼ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’ä½œæˆï¼ˆéè¡¨ç¤ºï¼‰
    root = tk.Tk()
    root.withdraw()  # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’éè¡¨ç¤º
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¤ã‚¢ãƒ­ã‚°ã§ç”»åƒã‚’é¸æŠ
    filetypes = [
        ("ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«", "*.jpg *.jpeg *.png *.bmp *.gif"),
        ("JPEGãƒ•ã‚¡ã‚¤ãƒ«", "*.jpg *.jpeg"),
        ("PNGãƒ•ã‚¡ã‚¤ãƒ«", "*.png"),
        ("ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«", "*.*")
    ]
    
    try:
        image_paths = filedialog.askopenfilenames(
            title="ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ç”»åƒã‚’é¸æŠã—ã¦ãã ã•ã„ï¼ˆè¤‡æ•°å¯ï¼‰",
            filetypes=filetypes
        )
        
        if not image_paths:
            print("ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒé¸æŠã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
            return
            
    except Exception as e:
        print(f"ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return
    
    analyzer = AICalendarAnalyzer()
    
    # è¨­å®šã‹ã‚‰ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼è¨­å®šã‚’å–å¾—
    workflow_config = config_loader.get_workflow_config()
    
    print(f"é¸æŠã•ã‚ŒãŸç”»åƒãƒ•ã‚¡ã‚¤ãƒ«: {len(image_paths)}å€‹")
    for path in image_paths:
        print(f"  - {path}")
    
    all_found_dates = set()  # é‡è¤‡ã‚’é¿ã‘ã‚‹ãŸã‚setã‚’ä½¿ç”¨
    
    # å„ç”»åƒã‚’é †æ¬¡å‡¦ç†
    for i, image_path in enumerate(image_paths, 1):
        print(f"\n=== ç”»åƒ {i}/{len(image_paths)}: {os.path.basename(image_path)} ===")
        
        if not os.path.exists(image_path):
            print(f"ã‚¨ãƒ©ãƒ¼: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {image_path}")
            continue
        
        print("AIç”»åƒèªè­˜ã«ã‚ˆã‚‹ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼è§£æé–‹å§‹...")
        
        # AIç”»åƒèªè­˜ã‚’å®Ÿè¡Œ
        analysis_result = analyzer.analyze_calendar_image(image_path)
        
        if analysis_result:
            # æ—¥ä»˜ã‚’æŠ½å‡º
            found_dates = analyzer.extract_dates_from_analysis(analysis_result)
            
            # è¦‹ã¤ã‹ã£ãŸæ—¥ä»˜ã‚’çµ±åˆ
            for date_str in found_dates:
                all_found_dates.add(date_str)
        else:
            print("AIè§£æã«å¤±æ•—ã—ã¾ã—ãŸ")
    
    # çµ±åˆçµæœã‚’è¡¨ç¤º
    found_dates_list = sorted(list(all_found_dates))
    print(f"\n{'='*60}")
    print("çµ±åˆæ¤œç´¢çµæœ")
    print(f"{'='*60}")
    
    if found_dates_list:
        print(f"ã€Œç”°ã€ãŒæ›¸ã‹ã‚ŒãŸæ—¥ä»˜: {len(found_dates_list)}ä»¶")
        for date_str in found_dates_list:
            date_obj = datetime.datetime.fromisoformat(date_str).date()
            print(f"- {date_obj.strftime('%Yå¹´%mæœˆ%dæ—¥ (%A)')}")
        
        # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ï¼ˆæœ€åˆã®ç”»åƒã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ï¼‰
        if image_paths:
            output_dir = os.path.dirname(image_paths[0])
            results_path = os.path.join(output_dir, f"batch_ai_analysis_results.json")
            dates_path = os.path.join(output_dir, f"batch_den_dates.txt")
            
            analyzer.save_results(results_path)
            
            with open(dates_path, 'w', encoding='utf-8') as f:
                for date_str in found_dates_list:
                    f.write(f"{date_str}\n")
            print(f"æ—¥ä»˜ãƒªã‚¹ãƒˆã‚’ {dates_path} ã«ä¿å­˜ã—ã¾ã—ãŸ")
        
    else:
        print("ã€Œç”°ã€ãŒæ›¸ã‹ã‚ŒãŸæ—¥ä»˜ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

if __name__ == "__main__":
    main()

